<?xml version="1.0"?>
<?xml-stylesheet href="../scheduler.xsl" type="text/xsl"?>

<!--$Id$-->

<description
    title               = "Überlegungen des Jahres 2005 - Scheduler auf hundert Rechnern"
    base_dir            = "../"
    parent_page         = "index.xml"
    author              = "$Author$"
    date                = "$Date$"
    document_state      = "work_in_progress"
>
    <!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-->

    <scheduler_table_of_content/>

    <p align="right">8. März 2005</p>

    <h2>Methode zur Ausführung von XML-Kommandos</h2>
    <p>
        XML-Kommandos können auch über eine spooler-Methode übergeben werden:
    </p>

    <pre>var xml_antwort = spooler.execute_xml( "&lt;job name='xx'> &lt;script...> &lt;/job>" );
var xml_antwort = spooler.execute_xml( "&lt;show_state/"> );</pre>

    <p>
        Bei einem Fehler wird wie bei TCP keine Exception, sondern das Element &lt;ERROR> geliefert. (ok?)
    </p>




    <h2>Jobs hinzufügen und entfernen</h2>

    <h3>XML-Kommando&#160; &lt;job></h3>
    <p>
        Arbeitet im Prinzip wie &lt;add_job>, erlaubt es aber, ein echtes Fragment der Konfiguration zu übergeben. 
        In der steht ja &lt;job> und nicht &lt;add_job>.
    </p>
    <p>
        Wenn der Job bereits existiert, wird er überschrieben, als wäre er in einer &lt;base>-Konfiguration festgelegt worden. 
    </p>

    <h3>Methode spooler.job_exists( "jobname" )</h3>
    <p>
    Die Methode liefert true, genau dann wenn der Job bekannt ist.
    </p>

    <h3>Methode spooler.remove_job( "jobname" )</h3>
    <p>
    Die Methode  entfernt einen Job.
    </p>

    <p>
        Ändern oder Entfernen eines Jobs kann nur unter bestimmten Bedingungen erfolgen:
    </p>

    <ul>
        <li>
            Keine Task darf laufen
        </li>
        <li>
            Der Job darf nicht in einer Jobkette sein
        </li>
        <li>
            ... (muss ich noch prüfen)
        </li>
    </ul>



    <h2>Aufträge entfernen</h2>
    <h3>Methode job_chain.remove_order( order_id )</h3>
    <p>
        Entfernt den Auftrag.
        Wenn eine Task den Auftrag gerade verarbeitet, wird er nach der Verarbeitung gelöscht (unabhängig von seinem Zustand). 
    </p>



    <h2>Methode spooler.start_process()</h2>
    <p>
        Damit kann ein Shell-Skript gestartet werden.
        Parameter wie bei <code>&lt;process></code>.
        Rückgabewert ist ein Objekt mit der Methode <code>wait()</code>.
    </p>
    <pre>var process = spooler.start_process( "/xxx/shellscript", parameter, umgebungsvariablen );
process.timeout = 120;                      // Danach automatisches kill?
spooler_log.info( "pid=" + process.pid );

var is_terminated process.wait( 60.0 );    // 60s aufs Ende warten
spooler_log.info( process.exit_code );</pre>

    <p>
        <code>add_pid()</code> ist inklusive.
    </p>


    <h2>Shell-Skripte als Auftragsjobs zulassen</h2>
    <p>
        Auch ein Shell-Skript kann Auftragsgesteuert (<code>order="yes"</code>) sein.
        Das Skript wird einfach für jeden Auftrag aufgerufen. Der Auftrag wird nicht übergeben.
    </p>
    <p>
        (Später könnten wir Teile des Auftrags als Skript-Parameter oder mit Umgebungsvariablen übergeben.)
    </p>




    <h2>Auftragsjobs, die sich nach jedem Auftrag beenden</h2>

    <ul>
        <li>
            Explizit durch spooler_task.end() in spooler_process().
        </li>
        <li>
            Oder ich baue ein, dass das Skript nach einem Auftrag beendet wird, wenn spooler_process() nicht implementiert ist.
        </li>
    </ul>

    <p>
        Wenn spooler_process() nicht implementiert ist, wird anscheinend false als Rückgabe angenommen. Der Auftrag landet dann im Fehlerzweig der Jobkette.
        Lösung: Fehlerzweig und Erfolgszeig gleich machen:  job_chain.add_job( status, folgestatus, folgestatus, "einfacher job" ). Wenn spooler_process() fehlt, können Erfolg und Fehler ohnehin nicht unterschieden werden.
    </p>




    <h2>&lt;run_time> für Aufträge</h2>

    <p>
        Der &lt;run_time>-Mechanismus wird auch für Aufträge gelten.
        Die Attribute begin=, end= und let_run= sind nicht erlaubt, statt dessen single_start=.
    </p>
    <p>
        &lt;period>, &lt;date>, &lt;weekdays>, &lt;ultimos> und &lt;holidays> sind erlaubt.
        (Der Name von &lt;period> ist bei einem Auftrag nicht ganz richtig, es ist ja ein Zeitpunkt.)
    </p>
    <p>
        Default ist &lt;run_time once="yes"/>.
    </p>
    <p>
        Wenn ein Auftrag einen Endzustand erreicht hat (add_end_state), dann prüfe ich, ob in &lt;run_time> eine Wiederholung vorgesehen ist. Wenn ja, setze ich den Auftrag auf seinen Anfangszustand zurück. state_text lösche ich. Die Id bleibt dieselbe.
    </p>
    <p>
        Wenn es keine Wiederholung gibt, lösche ich wie bisher den Auftrag. (Hier muss ich den Algorithmus erweitern, um dies sicher festzustellen, das war bei Jobs nicht nötig, da ich jede Mitternacht erneut prüfe.)
    </p>
    <p>
        Run_time wird gesetzt mit: <code>order.run_time_xml = "&lt;run_time ...>"</code>. 
    </p>
    <p>
        Methoden für &lt;run_time>: Wenn du willst, mache ich auch ein run_time-Objekt. Etwa so: order.run_time.add_start( "2005-04-01 12:00" ). Damit können die Startzeiten programmiert verändert werden. Das gilt dann auch für Jobs.
    </p>




    <h2>Verteilte Scheduler mit unabhängigen, lose gekoppelten Scheduler</h2>

    <p>
        Scheduler können sich an einen steuernden Scheduler anschließen. 
        Wenn die Verbindung unterbrochen wird, versuchen die Scheduler sie wieder aufzubauen, laufen aber ungestört weiter.
        Jeder Scheduler hat seine eigene XML-Konfiguration, ist also unabhängig.
    </p>
    <p>
        Der Begriff Nebenscheduler passt hier nicht gut, denn diese Scheduler können selbstständig laufen.
    </p>
    <p>
        Wenn du willst, kann nach Unterbrechung der Verbindung der Scheduler eine neue Verbindung zu einem alternativen steuernden Scheduler aufbauen, der auf einem anderen Rechner läuft.
    </p>

    <h3>Was kann der steuernde Scheduler?</h3>
    <ul>
        <li>
            Jobs können auf anderen Rechnern (Nebenschedulern) laufen.
        </li>
        <li>
            Jobketten können solche verteilten Jobs enthalten.
        </li>
        <li>
            Der steuernde Scheduler kann (via TCP) Informationen über die angeschlossenen Scheduler liefern.
        </li>
    </ul>

    <h3>Verteilte Jobs</h3>
    <p>
        In seiner XML-Konfiguration können Jobs bekannt gegeben werden, die unter anderen Schedulern laufen. Die Jobskripte selbst werden im jeweiligen Scheduler definiert. (Erweiterung: Die Jobs werden vollständig vom steuernden Scheduler übertragen, was aber bei Java schwierig ist.)
    </p>
    <p>
        Im steuernden Scheduler sieht das so aus:
    </p>
    <pre>&lt;job name="ein_job" order="yes" scheduler="host-a:4444"/></pre>

    <h3>Jobketten mit verteilten Jobs</h3>
    <p>
        Ein einem anderen Rechner zugewiesener Job kann in eine Jobkette aufgenommen werden. 
        Der steuernde Scheduler übergibt Aufträge dann an den Nebenscheduler.
    </p>
    <p>
        Dazu hält nur der steuernde Scheduler die Jobkette.
        Wenn ein Auftrag an einem externen Job übergeben werden soll, geschieht folgendes.
    </p>
    <ul>
        <li>
            Die Verbindung zum Nebenscheduler wird geprüft.
            Ist sie unterbrochen, gibt's eine Warnung und der steuernde Scheduler erwartet den Verbindungsaufbau des Nebenschedulers.
        </li>
        <li>
            Der steuernde Scheduler leiht den Auftrag vollständig (inklusive <code>payload</code>) an den Nebenscheduler aus.
            Er tut dies nur, wenn der Nebenscheduler den Auftrag sofort verarbeiten kann.
        </li>
        <li>
            Der Nebenscheduler führt den Auftrag aus (führt einen <code>spooler_process()</code> aus).
        </li>
        <li>
            Im Datenbankbetrieb ändert der Nebenscheduler Datensatz des Auftrags in der Datenbank.
            (Wie stellen wir sicher, dass der Nebenscheduler mit einer Datenbank, und zwar derselben, arbeitet?)
        </li>
        <li>
            Der Nebenscheduler gibt den Auftrag (mit neuem Zustand und anderen Änderungen, auch in der <code>payload</code>) 
            an den steuernden Scheduler zurück.
        </li>
        <li>
            Wenn das nicht geht, weil die Verbindung unterbrochen ist: 
            Der steuernde Scheduler löscht (oder kennzeichnet) die Aufträge, die an den verlorengegangenen Nebenscheduler ausgeliehen sind.
            Diese Aufträge werden also nicht weiter verwendet.
        </li>
        <li>
            Wenn der Nebenscheduler die Verbindung wiederhergestellt hat,
            fragt der steuernde Scheduler den Nebenscheduler nach dem Zustand des Auftrags.
            Falls der Nebenscheduler neu gestartet worden ist, hat er den Zustand des Auftrags aus der Datenbank gelesen.
            Ohne Datenbankbetrieb wissen wir nichts über den Auftrag. 
            Wir könnten annehmen, dass der Jobschritt nicht ausgeführt worden ist und 
            den Auftrag auf den Zustand vor der Ausleihe zurücksetzen.
        </li>
        <li>
            Die Details überlege ich mir noch.
        </li>
    </ul>

    <h3>&lt;run_time>?</h3>
    <p>
        Evtl. kann auch die <code>&lt;run_time></code> im steuernden Scheduler definiert sein (dann sollte sie nicht im Nebenscheduler definiert sein).
        Der steuernde Scheduler kann dann Tasks entsprechend seiner <code>&lt;run_time></code> starten, die dann unter dem Nebenscheduler laufen.
    </p>

    <h3>Zentrale Überwachung durch den steuernden Scheduler</h3>
    <p>
        Die HTML- oder PHP-Oberfläche kann durch eine TCP-Verbindung mit dem steuernden Scheduler Informationen über alle angeschlossenen Scheduler erhalten.
    </p>
    <p>
        Eine neue Abfrage würde eine Liste der angeschlossenen Scheduler liefern 
        (mit TCP-Adressen, so dass die HTML/PHP-Anwendung eigene Verbindungen zu den angeschlossenen Schedulern aufbauen kann).
    </p>
    <p>
        Das könnte auf zwei verschiedene Weisen implementiert werden:
    </p>
    <ul>
        <li>
            Der steuernde Scheduler bittet alle angeschlossenen Scheduler um ihren Status. Das geschieht für alle gleichzeitig und asynchron, also nicht blockierend. Nur Antworten, die innerhalb einer kurzen Frist (vielleicht eine halbe Minute) eintreffen, werden berücksichtigt. Das, damit irgendein verklemmter Scheduler (z.B. wegen NFS) nicht alles blockiert. Die Frist wirst du angeben können: &lt;show_state timeout="30">. In der Regel sollte ein Scheduler innerhalb einer Sekunde antworten.
        </li>
        <li>
            Um die rekursiven Abfragen zu vermeiden, versorgen die angeschlossenen Scheduler den steuernden regelmäßig mit Informationen. Der steuernde Scheduler braucht die anderen Scheduler dann nicht mehr zu fragen. Das hat den Vorteil, dass er sofort antwortet, und den Nachteil, dass die Informationen nicht so aktuell sind und es viel TCP-Verkehr gibt. Gefällt mir nicht so gut.
        </li>
    </ul>


    <h2>Verteilte Scheduler mit abhängigen, eng gekoppelten Nebenschedulern</h2>
    <p>
        Bei dieser zweiten Lösung wären die Nebenscheduler völlig vom steuernden Scheduler abhängig.
        Sie brauchen kaum eine XML-Konfiguration.
    </p>
    <p>
        Sie dienen nur dazu, Jobs des steuernden Scheduler zu starten.
        Diese Jobs müssen in eigenen Prozessen laufen
        und arbeiten direkt mit dem steuernden Scheduler zusammen, nicht mit dem Nebenscheduler.
    </p>
    <p>
        Das ist im Prinzip dasselbe wie bisher mit nur einem Scheduler, nur dass der Prozess, der den Job ausführt, auf einem anderen Rechner läuft.
        Alle Aufrufe (hin: <code>spooler_process()</code>, zurück: <code>spooler_log.info()</code>) werden über TCP, 
        d.h. übers Netzwerk abgewickelt. 
        Bei sehr vielen Aufrufen kann das eine Bremse sein.
    </p>
    <p>
        Eng gekoppelte Scheduler sind einfacher zu realisieren als lose gekoppelte.
    </p>
    <p>
        (Ein paar Dinge müssen noch geklärt werden. 
        Zum Beispiel kann der steuernde Scheduler nicht die Datei für stderr vorgeben, wenn der Prozess auf einem anderen Rechner läuft;
        <code>&lt;kill_task></code> muss über den Nebenscheduler abgewickelt werden)
    </p>



    <h2>Anarchisches Modell</h2>
    <p>
        Es gibt keinen Häuptling.
    </p>
    <p>
        Vorteile:
    </p>
    <ul>
        <li>
            Das ganze System der verteilten Jobs hängt nicht vom Häuptling ab.
        </li>
    </ul>
    <p>
        Nachteile:
    </p>
    <ul>
        <li>
            Keine zentrale Auskunft (außer über Datenbank).
        </li>
        <li>
            Keine zentrales Hauptprokoll
        </li>
        <li>
            Auftragsprotokolle nur in Fragmenten, weil die Aufträge verschiedene Rechner durchlaufen.
        </li>
        <li>
            Alle betroffenen Indianer müssen die Jobkette kennen. 
            Bei Änderung müssen sie neu gestartet werden.
        </li>
    </ul> 


    <h2>Medizinmannmodell</h2>
    <p>
        Das ist die Kombination aus lose gekoppelten und anarchischem Modell.
    </p>
    <p>
        Natürlich gibt es fast nur Vorteile:
    </p>
    <ul>
        <li>
            Der Häuptling steuert nichts.
            Er sammelt die Hauptprotokolle und die rechner-übergreifenden Auftragsprotokolle 
            und ist die zentrale Auskunft (für rekursives <code>&lt;show_state></code> usw.).
        </li>
        <li>
            Die Indianer reichen ihre Aufträge untereinander weiter (über die Datenbank).
        </li>
        <li>
            Die Indianer schicken dem Häuptling Statusänderungen und Protokolle 
            (jedes Protokoll in einfacher TCP-Verbindung).
        </li>
        <li>
            Der Häuptling schickt einem Indianer ein Signal, wenn ein neuer Auftrag vorliegt. 
        </li>
        <li>
            Der Adminstrator kann über den Häuptling Aufträge und Tasks unter anderen Indianern erzeugen.
        </li>
    </ul>
    <p>
        Und wenn der Häuptling nicht läuft:
    </p>
    <ul>
        <li>
            Die Indianer bemerken den Verlust der Verbindung zum Häuptling.
        </li>
        <li>
            Die Indianer sehen dann periodisch in der Datenbank nach, ob neue Aufträge (und vielleicht Tasks) vorliegen.
        </li>
        <li>
            Die Indianer schicken die Protokollausgaben nicht zum Häuptling.
        </li>
        <li>
            Wenn ein Protokoll endet, geht es verloren.
            <br/>
            (Aber der Indianer könnte die Datei stehen lassen und später dem Häuptling liefern,
            auch wenn der Auftrag oder die Task längst geendet hat.)
        </li>
        <li>
            Es könnte einstellbar sein, dass der Indianer auf den Häuptling wartet (pro Jobkette oder der gesamte Indianer).
        </li>
    </ul>
    <p>
        Wenn der Häuptling wieder läuft:
    </p>
    <ul>
        <li>
            Die Indianer und der Häuptling (falls er sich seiner Indianer erinnert) versuchen, sich wieder zu verbinden.
        </li>
        <li>
            Die Indianer liefern die aktuellen Zustände, damit der Häuptling aktuelle Auskunft geben kann.
        </li>
        <li>
            Die noch offenen Protokolle werden erneut übertragen.
        </li>
    </ul>

    <h3>Protokolldateien über NFS oder SMB</h3>
    <p>
        Möglicherweise können wir einen zentralen Fileserver voraussetzen, auf dem per NFS die Protokolle geschrieben werden.
        Dann könnte der Indianer, der den Auftrag beendet, selbst das Auftragsprotokoll in die Datenbank schreiben.
    </p>
    <p>
        Schwieriger ist es mit dem zentralen Hauptprotokoll: 
        Es ist nicht klar, ob NFS zuverlässig von mehreren Rechnern aus eine Datei gleichzeitig fortschreiben kann.
    </p>
    <p>
        Falls einmal Scheduler unter Windows hinzukommen sollten, würde das nicht funktionieren.
        Man müsste dann auf SMB umsteigen.
    </p>




    <h2>Vergleich der Methoden für verteilte Jobs</h2>
    <p>
        Jeder Scheduler kann selbständig arbeiten mit lokalen Jobs und lokalen Jobketten.
        Hier werden nur Jobketten mit verteilten Jobs betrachtet.
    </p>
    <p>
        Für alle Methoden gilt:
        Wenn ein Scheduler abbricht, egal ob Häuptling oder Indianer, dann sterben die von ihm gesteuerten Jobs.
        Wenn der Scheduler neu startet, liest er den Zustand aus der Datenbank:
    </p>
    <ul>
        <li>
            Gestartete Tasks sind verloren, sie werden nicht neu gestartet.
        </li>
        <li>
            Gerade verarbeitete Aufträge behalten ihren Zustand, d.h. der Jobschritt wird wiederholt.
        </li>
    </ul>

    <p>&#160;</p>
    <p>&#160;</p>
    <table cellspacing="0" cellpadding="0">
        <col style="padding-left: 0ex; font-weight: bold" valign="top"/>
        <col style="padding-left: 2ex" valign="top"/>
        <col style="padding-left: 2ex" valign="top"/>
        <col style="padding-left: 2ex" valign="top"/>
        <col style="padding-left: 2ex" valign="top"/>
        <col style="padding-left: 2ex" valign="top"/>
        
        <tr style="font-weight: bold">
            <td></td>
            <td>Monarchisch<br/>mit Häuptling, eng gekoppelt</td>
            <td>Fürstentümer<br/>mit Häuptling, lose gekoppelt</td>
            <td>Anarchisch<br/>ohne Häuptling</td>
            <td>Konstitutionelle Monarchie</td>
        </tr>
        
        <tr>
            <td>
            </td>    
            <td>
                Der Häuptling steuert alles unmittelbar. Er hat volle Kontrolle. 
                Er führt die Protokolle und hält die Objekte (Task, Order).
            </td>    
            <td>
                Der Indianer steuert den Job unmittelbar.
                Er führt die Protokolle und hält die Objekte (Task, Order).
            </td>    
            <td>
                Jeder Scheduler steuert seine Jobs und kann Jobs unter anderen Schedulern starten (ohne Rückmeldung)
                und kann Aufträge übergeben (ebenfalls ohne Rückmeldung).
            </td>
            <td>
                Anarchisch mit optionalen Häuptling (eher einem Medizinmann).
                Alles läuft auch ohne Häuptling, nur gibt es dann keine zentrale Auskunft.
            </td>
        </tr>
        
        <tr><td colspan="99"><hr size="1"/></td></tr>
        <tr>
            <td>
                Was passiert beim Abbruch eines Indianers?
            </td>    
            <td>
                Ein gestarteter Job läuft zuende, denn er kommuniziert nur mit dem Häuptling.
                Dieser Job kann auch Aufträge verarbeiten.
                Dazu wird der Indianer nicht gebraucht.
                <p/>
                Der Häuptling kann keine Jobs starten oder killen.
                Nach dem Neustart des Indianers ist das wieder möglich 
                (der Indianer muss dann einen kill auf einen ihm selbst unbekannten Prozess ausführen dürfen).
            </td>    
            <td>
                Der Job wird abbrechen, weil die Verbindung zu seinem Scheduler unterbrochen ist.
                <p/>
                Der Indianer verhält sich wie ein einfacher Scheduler:
                Beim Neustart liest der Scheduler den Zustand aus der Datenbank und setzt fort.
                <p/>
                Oder: Beim Neustart holt sich der Indianer den Zustand vom Häuptling.
            </td>    
            <td>
                Wie links (ohne die Häuptlingsoption)
            </td>    
            <td>
                Wie links
            </td>    
        </tr>

        <tr><td colspan="99">&#160;</td></tr>
        <tr>
            <td>
            </td>    
            <td>
                → Harmlos nach Neustart
            </td>    
            <td>
                → Wie Abbruch des bisherigen Schedulers
            </td>    
            <td>
                → Wie Abbruch des bisherigen Schedulers
            </td>    
            <td>
                → Wie Abbruch des bisherigen Schedulers
            </td>    
        </tr>

        
        <tr><td colspan="99"><hr size="1"/></td></tr>
        <tr>
            <td>
                Was passiert beim Abbruch des Häuptlings?
            </td>    
            <td>
                Der Häuptling ist wesentlich, ohne ihn läuft nichts (bis auf die selbständigen Aktivitäten der Indianer).
                Das ist wie bisher: ein Scheduler steuert alle Jobs, nur eben über mehrere Rechner hinweg.
            </td>    
            <td>
                Die Indianer führen ganze Jobs oder Auftragsschritte selbständig durch.
                <p/>
                Der Häuptling wartet nach einem Neustart auf die Anrufe der Indianer 
                (oder er ruft die Indianer an, wenn er ein Melderegister hat).
                Der Häuptling erhält dann von den Indianern den Zustand der ausgeliehenen Aufträge.
            </td>    
            <td>
                Nichts passiert.   
            </td>    
            <td>
                Die Indianer teilen dem Häuptling nichts mehr mit, laufen aber weiter.
                <p/>
                Der Häuptling fordert nach seinem Neustart von den Indianern aktuelle Informationen an.
                Die Protokolle werden (soweit noch geöffnet) erneut übertragen.
            </td>    
        </tr>
        
        <tr><td colspan="99">&#160;</td></tr>
        <tr>
            <td>
            </td>    
            <td>
                → Wie Abbruch des bisherigen Schedulers
                <br/>(betrifft nur die verteilten Jobs)
            </td>    
            <td>
                → Harmlos nach Neustart
            </td>    
            <td>
            </td>    
            <td>
                → Harmlos. Während des Abbruchs gibt es keine zentrale Information.
            </td>    
        </tr>


        <tr><td colspan="99"><hr size="1"/></td></tr>
        <tr>
            <td>
                Jobstart
            </td>
            <td>
                Entfernte Prozesse werden wie lokale Prozesse behandelt.
                <ul>
                    <li>Prozessstart über Indianer</li>
                    <li>Prozess verbindet sich direkt mit dem Häuptling</li>
                    <li>Indianer führt <code>kill_process</code> durch</li>
                </ul>
            </td>
            <td>
                Entfernte Prozesse werden vom jeweiligen Indianer gesteuert.
                Der Indianer teilt dem Häuptling das Ende der Task mit,
                vielleicht auch den Zustand <code>waiting_for_order</code>.
            </td>
            <td>
                Jeder Scheduler kann einen Job unter einem anderen Scheduler starten.
                Der andere Scheduler teilt dem ersten nichts mit.
            </td>
            <td>
                Jeder Indianer und der Häuptling können Jobs unter anderen Schedulern starten.
            </td>
        </tr>

        <tr><td colspan="99"><hr size="1"/></td></tr>
        <tr>
            <td>
                Jobkette mit verteilten Jobs
            </td>
            <td>
                Wie bisheriger Scheduler: der entfernte Prozess ist wie ein lokaler direkt angebunden.
                Der Häuptling ist genauso über den Job informiert als wäre es ein lokaler Prozess.
            </td>
            <td>
                Nur der Häuptling kennt die Jobkette.
                Der Häuptling leiht den Auftrag an den Indianer aus (über TCP oder Datenbank).
                Wenn der Auftrag verarbeitet ist (<code>spooler_process()</code> endet), 
                gibt der Indianer den Auftrag an den Häuptling zurück (inkl. payload, state usw.)
            </td>
            <td>
                Jeder beteiligte Scheduler kennt die Jobkette.
                Ein Scheduler kann den Auftrag an den nächsten der Jobkette übertragen
                (über TCP oder Datenbank).
                Anschließend kümmert sich dieser Scheduler um den Auftrag. 
                Der erste Scheduler vergisst den Auftrag.
            </td>
            <td>
                Wie links
            </td>
        </tr>

        <tr><td colspan="99"><hr size="1"/></td></tr>
        <tr>
            <td>
                Ändern der Jobkette
            </td>
            <td>
                Nur der Häuptling muss neu gestartet werden.
            </td>
            <td>
                Nur der Häuptling muss neu gestartet werden.
            </td>
            <td>
                Alle betroffenen Scheduler müssen neu gestartet werden.
            </td>
            <td>
                Wie links
            </td>
        </tr>

        <tr><td colspan="99"><hr size="1"/></td></tr>
        <tr>
            <td>
                Auftragsprotokoll
            </td>
            <td>
                Der Häuptling erstellt unmittelbar das Protokoll. Es ist stets aktuell.
            </td>
            <td>
                Der Häuptling bekommt das Protokoll des Jobschritts des Indianers am Ende des Jobsschritts via TCP.
                <p/>
                Es ist auch einstellbar, dass der Häuptling jede Protokollzeile sofort bekommt. 
                Damit ist das Auftragsprotokoll stets aktuell.
                (Der TCP-Verkehr kann optimiert werden, wenn die Protokollzeilen kontinuierlich über eine eigene Verbindung übertragen werden.)
            </td>
            <td>
                Es gibt keine zentrale Stelle für das Auftragsprotokoll (evtl. gemeinsamer Dateizugriff über NFS/SMB möglich?).
                Für jeden Job, den der Auftrag durchläuft, gibt es ein Prokokoll.
                Man könnte nach jedem Jobschritt das bisherige Protokoll aus dem BLOB lesen 
                und um den neuen Jobschritt erweitert zurückschreiben.
                Oder die Fragmente separat speichern (1:n) und von der Oberfläche zusammensetzen lassen.
            </td>
            <td>
                Solange der Häuptling läuft, kann er das Auftragsprotokoll führen.
                Wenn er nicht läuft, haben wir Fragmente.
            </td>
        </tr>

        <tr><td colspan="99"><hr size="1"/></td></tr>
        <tr>
            <td>
                Hauptprotokoll
            </td>
            <td>
                Es gibt nur ein Hauptprotokoll.
                (bis auf die selbstständigen, vom Häuptling unabhängigen Aktivitäten der Indianer).
            </td>
            <td>
                Jeder Indianer hat sein eigenes Hauptprotokoll.
                Bestimmte Operationen (oder alle) kann ein Indianer auch dem Häuptling melden,
                der sie in sein Hauptprotokoll übernimmt.
            </td>
            <td>
                Kein zentrales Hauptprotokoll.
            </td>
            <td>
                Solange der Häuptling läuft, haben wir ein zentrales Hauptprotokoll.
                Sonst einzelne Hauptprotokolle.
            </td>
        </tr>
    </table>



</description>